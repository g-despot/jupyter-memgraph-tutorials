{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Graph Analytics on Large Scale Graphs Effortlessly with Nvidia and Memgraph \n",
    "\n",
    "Through this short tutorial, you will see how to use **Memgraph** and perform various graph analytics in terms of seconds on Facebook dataset containing more then 1 million edges using **Nvidia cuGraph** and **Memgraph**. If you have a huge dataset on which you want to run analytics, you can import it in **Memgraph** by using **Python**, any then use any of the following algorithms:\n",
    "\n",
    "* Balanced Cut [clustering]\n",
    "* Spectral Clustering \n",
    "* HITS [hubs vs authorities analytics]\n",
    "* PageRank\n",
    "* Leiden [community]\n",
    "* Louvain [community]\n",
    "* Katz Centrality \n",
    "* Betweenness Centrality \n",
    "\n",
    "All above algorithms are powered by **Nvidia** and they will execute on **GPU**. Of course, you will still need to query database by using **Cypher** language, but it is pretty simple and straigthforward. You can think of Cypher as SQL for graph databases. It contains many of the same language constructs like `CREATE`, `UPDATE`, `DELETE`... and it's used to query the database.\n",
    "\n",
    "Before we start, here is a short summary of things you can do from now on with **Memgraph** and **Nvidia**:\n",
    "* efortlessly import data inside graph database\n",
    "* run  analytics on graphs and get results really fast - up to 4 seconds for 1.3M edges graph\n",
    "* run GPU algorithm from graph database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "In this tutorial we will use following tech, and in order to follow you will need to install:\n",
    "\n",
    "- [Jupyter](https://jupyter.org/install)\n",
    "- [Docker](https://docs.docker.com/get-docker/)\n",
    "- [GQLAlchemy](https://pypi.org/project/gqlalchemy/)\n",
    "\n",
    "Docker is used because Memgraph is a native Linux application and cannot be installed on Windows and macOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation using Docker\n",
    "\n",
    "After installing Docker, you can set up Memgraph by running:\n",
    "\n",
    "```\n",
    "docker run -it -p 7687:7687 -p 3000:3000 -p 7444:7444 memgraph/memgraph-platform\n",
    "```\n",
    "\n",
    "This command will start the download and after it finishes, run the Memgraph container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Memgraph with GQLAlchemy\n",
    "\n",
    "We will be using the **GQLAlchemy** object graph mapper (OGM) to connect to Memgraph and execute **Cypher** queries easily from **Python**. GQLAlchemy also serves as a Python driver/client for Memgraph. Go to our [installation](https://memgraph.com/docs/gqlalchemy/) page to check how to install it. It is pretty straigthforward and you can install it with `pip`.\n",
    "\n",
    "\n",
    "In the next few steps we will do the following:\n",
    "* we will show you how to import large dataset from **CSV** file inside **Memgraph** in terms of seconds. \n",
    "* then you will see how to perform `PageRank` and `Louvain community detection` all by using **Python**\n",
    "\n",
    "But before we continue, we need to import `GQLAlchemy`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `qglalchemy` and connect to **Memgraph** using `host` and `port`. And we will clear our database, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gqlalchemy import Memgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph = Memgraph(\"127.0.0.1\", 7690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph.drop_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV** files containing **Facebook** dataset have the following structure:\n",
    "```\n",
    "node_1,node_2\n",
    "0,1794\n",
    "0,3102\n",
    "0,16645\n",
    "```\n",
    "Dataset constists of Facebook pages (from November 2017). It represent blue verified Facebook page networks of different categories. Nodes represent the pages and edges are mutual likes among them. The nodes are reindexed (start from 0) in order to achieve a certain level of anonimity. In order for **Memgraph** to import queries really fast, we will create index for node with label `Page` on `id` property.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph.execute(\n",
    "    \"\"\"\n",
    "    CREATE INDEX ON :Page(id);\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list out all the csv files we have from `data` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "csv_dir_path = os.path.abspath(\"./data/facebook_clean_data/\")\n",
    "csv_files = [join(csv_dir_path, f) for f in listdir(csv_dir_path) if isfile(join(csv_dir_path, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file_path in csv_files:\n",
    "    memgraph.execute(\n",
    "        f\"\"\"\n",
    "        LOAD CSV FROM \"{csv_file_path}\" WITH HEADER AS row\n",
    "        MERGE (p1:Page {{id: row.node_1}}) \n",
    "        MERGE (p2:Page {{id: row.node_2}}) \n",
    "        MERGE (p1)-[:LIKES]->(p2);\n",
    "        \"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "Now, we will execute PageRank to find important pages of a Facebook dataset. To read more about how does **Pagerank** work, you can go to our **[docs]()** page. All algorithms mentioned in [introduction](#introduction) part are developed by **Nvidia** and now are integrated under **MAGE - Memgraph Advanced Graph Extensions** . Our goal in **Memgraph** is for you to have it very easy when it comes to using algorithms on graph database and getting results really fast. They are implemented in C++ or Python. You don't need to understand how all those pieces are connected together in order to execute PageRank.\n",
    "\n",
    "You can do it with following line and you will get results in ~4 seconds for 1.3 million edges graph. In other part of query we will create and set `rank` property of node to value that `cugraph.pagerank` algorithm returned under variable `rank` for every `node`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "  memgraph.execute(\n",
    "        \"\"\"\n",
    "        CALL cugraph.pagerank.get() YIELD node,rank\n",
    "        SET node.rank = rank;\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ranks are ready and you can retrieve them with following Python call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node id: 50493, rank: 0.0030278728385218327\n",
      "node id: 31456, rank: 0.0027350282311318468\n",
      "node id: 50150, rank: 0.0025153975342989345\n",
      "node id: 48099, rank: 0.0023413620866201052\n",
      "node id: 49956, rank: 0.0020696403564964\n",
      "node id: 23866, rank: 0.001955167533390466\n",
      "node id: 50442, rank: 0.0019417018181751462\n",
      "node id: 49609, rank: 0.0018211204462452515\n",
      "node id: 50272, rank: 0.0018123518843272954\n",
      "node id: 49676, rank: 0.0014821440895415787\n"
     ]
    }
   ],
   "source": [
    "results =  memgraph.execute_and_fetch(\n",
    "        \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN n.id as node, n.rank as rank\n",
    "        ORDER BY rank DESC\n",
    "        LIMIT 10;\n",
    "        \"\"\"\n",
    "    )\n",
    "for dict_result in results:\n",
    "    print(f\"node id: {dict_result['node']}, rank: {dict_result['rank']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will be available in dictionary form. One more thing you can do is visualize results with **Memgraph Lab**. Besides creating beautiful visualizations powered by D3.js and our graph style script, you can use **Memgraph Lab** to query graph database write your own graph algorithms in **Python or C++ or even Rust**, check Memgraph Database Logs, visualize graph schema. If you don't have any idea on which dataset you can do it, there are plenty of datasets available for you to start and explore. \n",
    "\n",
    "Now, let's find top 3 Pages and visualize their relationships in graph. We will use following query in Memgraph Lab:\n",
    "```\n",
    "MATCH (n)\n",
    "WITH n\n",
    "ORDER BY n.rank DESC\n",
    "LIMIT 3\n",
    "MATCH (n)<-[e]-(m)\n",
    "RETURN *;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that's it considering PageRank, next you will see how to use Louvain community detection in order to get communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain modularity maximization\n",
    "From our [docs](https://memgraph.com/docs/mage/query-modules/cpp/community-detection) page:\n",
    "> The Louvain algorithm belongs to the modularity maximization family of community detection algorithms. Each node is initially assigned to its own community, and the algorithm uses a greedy heuristic to search for the community partition with the highest modularity score by merging previously obtained communities.\n",
    "\n",
    "What it means is that connected Louvain algorithm measuers how connected are the nodes within a community if we would compare them to how connected they would be in a random network. Also it recursively merges communities into a single node and executes the modularity clustering on the condensed graphs. This is a one of the most popular community detection algorithms. Let's run it to find how many communities we have inside graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph.execute(\n",
    "    \"\"\"\n",
    "    CALL cugraph.louvain.get() YIELD cluster_id, node\n",
    "    SET node.cluster_id = cluster_id;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, let us find number of communities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2664\n"
     ]
    }
   ],
   "source": [
    "results =  memgraph.execute_and_fetch(\n",
    "        \"\"\"\n",
    "        MATCH (n)\n",
    "        WITH DISTINCT n.cluster_id as cluster_id\n",
    "        RETURN count(cluster_id ) as num_of_clusters;\n",
    "        \"\"\"\n",
    "    )\n",
    "# we will get only 1 result\n",
    "result = list(results)[0]\n",
    "\n",
    "#don't forget that results are saved in a dict\n",
    "print(f\"Number of clusters: {result['num_of_clusters']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can also visualize some of these communities. You can for example find nodes that belong to one communities, but are connected to other node that belongs in opposing communities.\n",
    "As for Louvain, it tries to minimize that number of nodes, so we shoudn't see that many of them. In Memgraph Lab try to execute following query:\n",
    "\n",
    "```\n",
    "MATCH  (n2)<-[e1]-(n1)-[e]->(m1)\n",
    "WHERE n1.cluster_id != m1.cluster_id AND n1.cluster_id = n2.cluster_id\n",
    "RETURN *\n",
    "LIMIT 1000;\n",
    "```\n",
    "\n",
    "Here is the graph style script we used to create this beautiful colorizations:\n",
    "\n",
    "#### insert image\n",
    "\n",
    "You can read more about background of such color scheme from our [blog post](https://memgraph.com/blog/optimizing-telco-networks-with-graph-coloring-and-memgraph-mage)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
