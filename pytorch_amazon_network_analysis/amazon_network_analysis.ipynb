{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f0aec3-5623-4346-822f-e4c07c2df8c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exploring a Amazon data network in Memgraph\n",
    "\n",
    "Through this short tutorial, you will learn how to install Memgraph, connect to it from a Jupyter Notebook and perform data analysis on Amazon data set using **graph neural network** called **Temporal graph networks**.\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "For this tutorial, you will need to install:\n",
    "\n",
    "- [Jupyter](https://jupyter.org/install)\n",
    "- [Docker](https://docs.docker.com/get-docker/)\n",
    "- [GQLAlchemy](https://pypi.org/project/gqlalchemy/)\n",
    "\n",
    "Docker is used because Memgraph is a native Linux application and cannot be installed on Windows and macOS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204a2ba-f32b-4d24-860d-b3912b602531",
   "metadata": {},
   "source": [
    "## 2. Installation using Docker\n",
    "\n",
    "After you install Docker, you can set up Memgraph by running:\n",
    "\n",
    "```\n",
    "docker run -it -p 7687:7687 -p 3000:3000 -p 7444:7444 memgraph/memgraph-platform\n",
    "```\n",
    "\n",
    "This command will start the download and after it finishes, run the Memgraph container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5304b7-3904-4384-b22d-a03d33b24c1c",
   "metadata": {},
   "source": [
    "## 3. Connecting to Memgraph with GQLAlchemy\n",
    "\n",
    "We will be using the **GQLAlchemy** object graph mapper (OGM) to connect to Memgraph and execute **Cypher** queries easily. GQLAlchemy also serves as a Python driver/client for Memgraph. You can install it using:\n",
    "\n",
    "```\n",
    "pip install gqlalchemy\n",
    "```\n",
    "\n",
    "> **Hint**: You may need to install [CMake](https://cmake.org/download/) before installing GQLAlchemy.\n",
    "\n",
    "Maybe you got confused when I mentioned Cypher. You can think of Cypher as SQL for graph databases. It contains many of the same language constructs like `CREATE`, `UPDATE`, `DELETE`... and it's used to query the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809da00f-9092-42bf-9fa8-153aa8722717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gqlalchemy import Memgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8bdec6-a3aa-4af4-b98d-b8d728aea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph = Memgraph(\"127.0.0.1\", 7687)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68f1ce-88b4-4838-be90-983c6d991eaa",
   "metadata": {},
   "source": [
    "Let's make sure that Memgraph is empty before we start with anything else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754e06dc-7c9f-41b9-9000-50db47550fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph.drop_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca06c5b-98a3-4b8e-8d2a-e6b4f30e37b8",
   "metadata": {},
   "source": [
    "Following command should output {number_of_nodes:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028abdc-ca8b-41f5-a02c-e49da103be4d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results = memgraph.execute_and_fetch(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN count(n) AS number_of_nodes ;\n",
    "    \"\"\"\n",
    ")\n",
    "print(next(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213b84b-805c-4a02-8f86-415a34872df8",
   "metadata": {},
   "source": [
    "## 4. Data analysis on Amazon product dataset\n",
    "\n",
    "You will load an **amazon product dataset** as list of cypher queries. One example of such query is following one:\n",
    "```cypher\n",
    "MERGE (a:User {id: 'A1BHUGKLYW6H7V', profile_name:'P. Lecuyer'})\n",
    "MERGE (b:Item {id: 'B0007MCVQ2'})\n",
    "MERGE (a)-[:REVIEWED {review_text:'Like all Clarks, these guys didnt disappoint. They fit great and look even better. For the price, I dont think a better deal exists out there for casual shoes.',\n",
    "  feature: [161.0, 133.0, 0.782608695652174, 0.0, 0.031055900621118012, 0.17391304347826086, 0.043478260869565216, 36.0, 36.0, 1.0, 3.6944444444444446, 0.0, 0.0, 3.0, 1.0, 12.0, 0.055, 0.519, 0.427, 0.9238],\n",
    "  review_time:1127088000, review_score:5.0}]->(b);\n",
    "```\n",
    "So as you can see, we have `User` and we have `Item` in our graph sheme. Every user has left a very **positive** review for **Item**. This wasn't a case for all reviews in original dataset, but we processed it and removed negative reviews (all reviews with `review_score` <= 3.0).\n",
    "Every `User` as an `id` and every `Item` user has reviewed has also an `id`. In this one query, we find the `User` and the `Item` with mentioned ids or we create one if such `User` or `Item` is missing in database. And we create an interaction event between them in term of an `edge` which has list of **20** edge features. This `edge_features` we created from review user has left to an item:\n",
    "\n",
    "1. Number of characters\n",
    "2. Number of characters without counting white space\n",
    "3. Fraction of alphabetical characters\n",
    "4. Fraction of digits\n",
    "5. Fraction of uppercase characters\n",
    "6. Fraction of white spaces\n",
    "7. Fraction of special characters, such as comma, exclamation mark, etc.\n",
    "8. Number of words\n",
    "9. Number of unique works\n",
    "10. Number of long words (at least 6 characters)\n",
    "11. Average word length\n",
    "12. Number of unique stopwords\n",
    "13. Fraction of stopwords\n",
    "14. Number of sentences\n",
    "15. Number of long sentences (at least 10 words)\n",
    "16. Average number of words per sentence\n",
    "17. Positive sentiment calculated by VADER\n",
    "18. Negative sentiment calculated by VADER\n",
    "19. Neutral sentiment calculated by VADER\n",
    "20. Compound sentiment calculated by VADER\n",
    "\n",
    "\n",
    "We should also prepared features for a `User`  and `Item`, but following features seemed enough for our **toy** example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d75e4-1433-4f46-bca8-5e3e02df4943",
   "metadata": {},
   "source": [
    "One more **note**: In those dataset of queries we already prepared for you, there is one query that will change \"working mode\" of our **temporal graph networks** module to **evaluation(eval)** mode. When mode is changed for **tgn** it also stops doing **training** of the model, and starts doing evaulation of trained model.\n",
    "If you look inside of file you should find following query:\n",
    "\n",
    "```cypher\n",
    "CALL tgn.set_mode(\"eval\") YIELD *;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf3673-97ff-46e6-b044-17ea8d4bbf03",
   "metadata": {},
   "source": [
    "### Trigger creation\n",
    "In order to process a dataset, we need to create trigger on **edge create** event if trigger with our name already doesn't exist. \n",
    "\n",
    "You will see, this check is a neat feature to have in your Jupyter notebook if you want just to rerun it without dumping **local Memgraph** instance if you are not working with **Docker**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825eb1b1-c261-47dd-8457-6ef0ff23dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger already exists\n"
     ]
    }
   ],
   "source": [
    "results = memgraph.execute_and_fetch(\"SHOW TRIGGERS;\")\n",
    "\n",
    "trigger_exists = False\n",
    "for result in results:\n",
    "    if result['trigger name'] == 'create_embeddings':\n",
    "            print(\"Trigger already exists\")\n",
    "            trigger_exists = True\n",
    "            break;\n",
    "              \n",
    "\n",
    "if not trigger_exists:\n",
    "    memgraph.execute(\n",
    "        \"\"\"\n",
    "        CREATE TRIGGER create_embeddings ON --> CREATE BEFORE COMMIT\n",
    "        EXECUTE CALL tgn.update(createdEdges) RETURN 1;\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Index creation for dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Memgraph** works best with **indexes** defined for nodes, in our case we will have **User** and **Item** types.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "index_queries = [\"CREATE INDEX ON :User(id);\",\n",
    "                \"CREATE INDEX ON :Item(id);\"]\n",
    "\n",
    "for query in index_queries:\n",
    "    results = memgraph.execute_and_fetch(query)\n",
    "    for result in results:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and evaluating Temporal Graph Networks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to train **Temporal graph networks** on **Amazon dataset** we will split dataset into **train** and **eval** queries. Let's first load our **raw queries**. Each query creates an **edge** between **User** and **Item**\n",
    "representing in such way **positive** review from **User** to certain **Item**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "with open(f\"{dir_path}/data/queries.cypherl\", \"r\") as fh:\n",
    "    raw_queries = fh.readlines()\n",
    "\n",
    "train_eval_split_ratio = 0.8\n",
    "queries_index_split = int(len(raw_queries) * train_eval_split_ratio)\n",
    "\n",
    "train_queries = raw_queries[:queries_index_split]\n",
    "eval_queries = raw_queries[queries_index_split:]\n",
    "\n",
    "print(f\"Num of train queries {len(train_queries)}\")\n",
    "print(f\"Num of eval queries {len(eval_queries)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we start importing **train** queries, first we need to set parameters for **temporal graph networks**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# since we are doing link prediction, we use self_supervised mode\n",
    "tgn_mode = \"self_supervised\"\n",
    "batch_size = 200 #optimal size as defined in paper\n",
    "num_layers = 2 # GNNs don't need multiple layers, contrary to CNNs.\n",
    "layer_type = \"graph_attn\" # choose between graph_attn or graph_sum\n",
    "function_type = \"identity\" # choose between identity or mlp\n",
    "message_aggregator_type = \"last\" # choose between last or mean\n",
    "memory_updater_type = \"gru\" # choose between gru or rnn\n",
    "attention_heads = 1\n",
    "memory_dimension = 100\n",
    "time_dimension = 100\n",
    "num_edge_features = 20\n",
    "num_node_features=20\n",
    "# number of sampled neighbors\n",
    "num_neighbors = 10\n",
    "# message dimension must be defined in the case we use MLP, because then we define dimension of **projection**\n",
    "message_dimension = time_dimension + num_node_features + num_edge_features\n",
    "\n",
    "tgn_param_query = f\"CALL tgn.set_params('{tgn_mode}', {batch_size}, {num_layers}, '{layer_type}', {memory_dimension}, {time_dimension}, {num_edge_features}, {num_node_features}, {message_dimension},{num_neighbors}, '{function_type}', '{message_aggregator_type}', '{memory_updater_type}', {attention_heads}) YIELD *;\"\n",
    "\n",
    "print(f\"TGN param query: {tgn_param_query}\")\n",
    "\n",
    "results = memgraph.execute_and_fetch(tgn_param_query)\n",
    "for result in results:\n",
    "    print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it is time to execute queries and do **first** epoch of **training**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0559e2e-bafe-4299-9a6c-f7439e786bf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for query in train_queries:\n",
    "    results = memgraph.execute_and_fetch(query.strip())\n",
    "    for result in results:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to change **TGN** mode to **eval** and start importing our **evaluation** queries."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "results = memgraph.execute_and_fetch(\"CALL tgn.set_mode('eval') YIELD *;\")\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "for query in eval_queries:\n",
    "    results = memgraph.execute_and_fetch(query.strip())\n",
    "    for result in results:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6acebec0-9c93-43f2-8de5-f0630455887f",
   "metadata": {},
   "source": [
    "After our **stream** is done, we should probably do few more rounds of training and evaluation in order to have properly working model. We can do so with following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94a5f4-fdc1-4323-8744-8208eabbf412",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results = memgraph.execute_and_fetch(\n",
    "    \"\"\"\n",
    "    CALL tgn.process_epochs(2) YIELD *\n",
    "    RETURN epoch_num, batch_num, round(accuracy * 100) / 100 as accuracy, round(batch_process_time * 100) / 100 as batch_process_time, accuracy_type ORDER BY epoch_num, batch_num;\n",
    "    \"\"\"\n",
    ")\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6a412-8eba-4131-a8d6-3041ce1482b7",
   "metadata": {},
   "source": [
    "If we want now to get only results of our model on batches of evaluation, we can write following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90307e3-3737-4796-b5a4-ac861a136faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = memgraph.execute_and_fetch(\n",
    "    \"\"\"\n",
    "        CALL tgn.get_results() YIELD  epoch_num, batch_num, accuracy, batch_process_time, accuracy_type\n",
    "        WITH epoch_num, batch_num, accuracy, batch_process_time, accuracy_type\n",
    "        WHERE accuracy_type = \"eval\" and epoch_num > 1\n",
    "        RETURN epoch_num, batch_num, round(accuracy * 100) / 100 as accuracy, round(batch_process_time * 100) / 100 as batch_process_time;\n",
    "    \"\"\"\n",
    ")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10068310-03be-4f6a-9f6e-9c67afe3d490",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And that is it :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}